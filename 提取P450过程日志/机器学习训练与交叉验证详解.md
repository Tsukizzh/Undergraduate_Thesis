# 机器学习训练与交叉验证（Fold）详解 - 零基础版

> **文档目的**：用最通俗的语言解释机器学习训练中的核心概念
> **面向读者**：完全零基础，从未接触过机器学习的人
> **以EZSpecificity项目为实例**
> **创建时间**：2026-01-06
> **更新时间**：2026-01-06（v4.0 优化组件讲解，更通俗易懂）

---

## 目录

0. [**核心：训练流程时间线（先看这个！）**](#第零章)
1. [从一个生活例子开始](#第一章)
2. [机器学习训练的本质是什么？](#第二章)
3. [为什么需要训练集、验证集、测试集？](#第三章)
4. [什么是Fold（交叉验证）？](#第四章)
5. [EZSpecificity的真实训练过程](#第五章)
6. [**实际训练组件详解（v3.0新增）**](#第六章)
7. [代码逐行解读](#第七章)
8. [常见问题解答](#第八章)

---

<a name="第零章"></a>
# 第零章：核心 - 训练流程时间线（先看这个！）

> **本章目的**：用一张时间线图，清晰展示epoch、batch、验证集、测试集、损失函数等概念**在什么时候被调用**，以及**它们之间的嵌套关系**。

---

## 0.1 一句话总结：整个训练过程的结构

```
整个训练 = 多轮Epoch → 每轮Epoch = 训练阶段 + 验证阶段 → 训练阶段 = 多个Batch
```

**类比**：
- **整个训练** = 一个学期（可能有100天）
- **一轮Epoch** = 一天的学习（上午学习 + 下午小测验）
- **一个Batch** = 一节课（学32道题）

---

## 0.2 完整时间线图（这是最重要的！）

下面这张图展示了**从训练开始到结束**，每个概念在什么时候被调用：

```
╔══════════════════════════════════════════════════════════════════════════════════╗
║                        机器学习训练完整时间线                                      ║
║                     （以EZSpecificity为例，使用Fold 0）                            ║
╚══════════════════════════════════════════════════════════════════════════════════╝

时间点 0                                                                        时间点 N
开始                                                                             结束
  │                                                                               │
  ▼                                                                               ▼
┌─────────────────────────────────────────────────────────────────────────────────┐
│【阶段1：数据准备】                                                               │
│                                                                                 │
│  程序做了什么：                                                                  │
│  ├── 读取 training_datas_0.csv  → 得到 439,887 条【训练集】                      │
│  ├── 读取 val_datas_0.csv       → 得到  43,988 条【验证集】                      │
│  └── 读取 testing_datas_0.csv   → 得到 102,640 条【测试集】                      │
│                                                                                 │
│  此时各概念的状态：                                                              │
│  ├── 训练集：已加载，马上要用                                                    │
│  ├── 验证集：已加载，每轮结束时用                                                │
│  ├── 测试集：已加载，但要等到最后才用！                                          │
│  ├── Epoch：还没开始                                                            │
│  ├── Batch：还没开始                                                            │
│  └── 损失函数：已定义，但还没计算                                                │
│                                                                                 │
└────────────────────────────────────────┬────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────────┐
│【阶段2：模型初始化】                                                             │
│                                                                                 │
│  程序做了什么：                                                                  │
│  ├── 创建神经网络结构                                                           │
│  ├── 随机初始化模型参数（几百万个数字）                                          │
│  ├── 创建优化器（Adam）← 决定"怎么学习"的工具                                   │
│  │   └── 类比：老师的教学方法（是死记硬背还是理解记忆？）                        │
│  ├── 设置初始学习率 lr=0.001 ← 决定"每次学多少"                                 │
│  │   └── 类比：学习的步子大小（太大会跳过重点，太小学太慢）                      │
│  └── 此时模型什么都不会，预测≈瞎猜                                              │
│                                                                                 │
└────────────────────────────────────────┬────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────────┐
│【阶段3：训练循环】← 这是核心！下面展开详细讲                                      │
│                                                                                 │
│  这个阶段会重复执行"一轮Epoch"，直到：                                           │
│  ├── 达到最大轮数（如100轮），或者                                               │
│  └── 触发早停（连续N轮验证集没有进步）                                           │
│                                                                                 │
│  ⚠️ 特别注意：前几轮有"热身期"（Warmup）                                         │
│  └── 类比：运动前先热身，学习率从小到大逐渐增加，避免一开始学太猛导致"抽筋"      │
│                                                                                 │
│  ┌───────────────────────────────────────────────────────────────────────────┐  │
│  │                                                                           │  │
│  │  for epoch in range(1, 101):  # 最多100轮，实际可能45轮就早停了            │  │
│  │                                                                           │  │
│  │      ╔═══════════════════════════════════════════════════════════════╗    │  │
│  │      ║【Epoch N 的训练阶段】使用【训练集】，会更新参数                 ║    │  │
│  │      ╠═══════════════════════════════════════════════════════════════╣    │  │
│  │      ║                                                               ║    │  │
│  │      ║  训练集有439,887条，每次取32条（batch_size=32）                ║    │  │
│  │      ║  所以要循环 439,887 ÷ 32 ≈ 13,746 次                          ║    │  │
│  │      ║                                                               ║    │  │
│  │      ║  for batch_idx in range(13746):  # 循环13,746次               ║    │  │
│  │      ║      │                                                        ║    │  │
│  │      ║      ├─【步骤A】取数据                                        ║    │  │
│  │      ║      │  batch = 训练集[batch_idx*32 : (batch_idx+1)*32]       ║    │  │
│  │      ║      │  # 取出32对(酶, 底物, 标签)                            ║    │  │
│  │      ║      │                                                        ║    │  │
│  │      ║      ├─【步骤B】模型预测                                      ║    │  │
│  │      ║      │  predictions = model(batch中的酶, batch中的底物)       ║    │  │
│  │      ║      │  # 得到32个预测值，如[0.8, 0.2, 0.9, 0.1, ...]        ║    │  │
│  │      ║      │                                                        ║    │  │
│  │      ║      ├─【步骤C】计算损失 ← 损失函数在这里被调用！             ║    │  │
│  │      ║      │  loss = BCEWithLogitsLoss(predictions, batch的label)   ║    │  │
│  │      ║      │  # loss是一个数字，表示预测有多"错"                    ║    │  │
│  │      ║      │  # 预测[0.8,0.2]，真实[1,0] → loss很小（预测对了）     ║    │  │
│  │      ║      │  # 预测[0.2,0.8]，真实[1,0] → loss很大（预测反了）     ║    │  │
│  │      ║      │                                                        ║    │  │
│  │      ║      └─【步骤D】更新参数 ← Adam优化器和学习率在这里工作！           ║    │  │
│  │      ║         optimizer.step(loss, lr=0.001)                        ║    │  │
│  │      ║         # Adam优化器：根据loss"智能地"调整模型参数              ║    │  │
│  │      ║         # 它会记住每个参数的历史变化，给变化大的参数"踩刹车"    ║    │  │
│  │      ║         # lr=0.001：每次只微调一点点（步子小，稳扎稳打）        ║    │  │
│  │      ║         # 如果在Warmup期：lr会更小，从0.000001逐渐增到0.001    ║    │  │
│  │      ║                                                               ║    │  │
│  │      ║  # 13,746个batch处理完 = 训练集所有数据都看了一遍 = 1个Epoch  ║    │  │
│  │      ║                                                               ║    │  │
│  │      ╚═══════════════════════════════════════════════════════════════╝    │  │
│  │                                      │                                    │  │
│  │                                      ▼                                    │  │
│  │      ╔═══════════════════════════════════════════════════════════════╗    │  │
│  │      ║【Epoch N 的验证阶段】使用【验证集】，不更新参数                 ║    │  │
│  │      ╠═══════════════════════════════════════════════════════════════╣    │  │
│  │      ║                                                               ║    │  │
│  │      ║  验证集有43,988条，同样每次取32条                              ║    │  │
│  │      ║  循环 43,988 ÷ 32 ≈ 1,375 次                                  ║    │  │
│  │      ║                                                               ║    │  │
│  │      ║  for batch_idx in range(1375):                                ║    │  │
│  │      ║      │                                                        ║    │  │
│  │      ║      ├─【步骤A】取数据                                        ║    │  │
│  │      ║      │  batch = 验证集[batch_idx*32 : (batch_idx+1)*32]       ║    │  │
│  │      ║      │                                                        ║    │  │
│  │      ║      ├─【步骤B】模型预测                                      ║    │  │
│  │      ║      │  predictions = model(batch)                            ║    │  │
│  │      ║      │                                                        ║    │  │
│  │      ║      └─【步骤C】记录预测结果（不计算损失！不更新参数！）       ║    │  │
│  │      ║         all_predictions.append(predictions)                   ║    │  │
│  │      ║         all_labels.append(batch的label)                       ║    │  │
│  │      ║                                                               ║    │  │
│  │      ║  # 验证集遍历完后，汇总计算评估指标                            ║    │  │
│  │      ║  val_auc = 计算AUC(all_predictions, all_labels)               ║    │  │
│  │      ║  val_aupr = 计算AUPR(all_predictions, all_labels)             ║    │  │
│  │      ║                                                               ║    │  │
│  │      ╚═══════════════════════════════════════════════════════════════╝    │  │
│  │                                      │                                    │  │
│  │                                      ▼                                    │  │
│  │      ╔═══════════════════════════════════════════════════════════════╗    │  │
│  │      ║【Epoch N 结束时的决策】                                        ║    │  │
│  │      ╠═══════════════════════════════════════════════════════════════╣    │  │
│  │      ║                                                               ║    │  │
│  │      ║  if val_auc > 历史最佳val_auc:                                 ║    │  │
│  │      ║      历史最佳val_auc = val_auc                                 ║    │  │
│  │      ║      保存当前模型到 best_model.ckpt   ← 保存最佳模型           ║    │  │
│  │      ║      耐心计数器 = 0                                           ║    │  │
│  │      ║  else:                                                        ║    │  │
│  │      ║      耐心计数器 += 1                                          ║    │  │
│  │      ║      if 耐心计数器 >= 20:            ← 早停判断                ║    │  │
│  │      ║          break  # 跳出训练循环                                ║    │  │
│  │      ║                                                               ║    │  │
│  │      ║  # 📉 学习率调度器在这里工作！（ReduceLROnPlateau）            ║    │  │
│  │      ║  if 连续10轮val_auc没提升:                                    ║    │  │
│  │      ║      lr = lr × 0.5   # 学习率减半！步子太大了，换小步走        ║    │  │
│  │      ║      # 类比：走大步没进展？试试小碎步，更精细地调整            ║    │  │
│  │      ║                                                               ║    │  │
│  │      ╚═══════════════════════════════════════════════════════════════╝    │  │
│  │                                                                           │  │
│  │      # 继续下一轮 Epoch...                                                │  │
│  │                                                                           │  │
│  └───────────────────────────────────────────────────────────────────────────┘  │
│                                                                                 │
└────────────────────────────────────────┬────────────────────────────────────────┘
                                         │
                                         ▼
┌─────────────────────────────────────────────────────────────────────────────────┐
│【阶段4：最终测试】← 测试集在这里才被使用！只用一次！                               │
│                                                                                 │
│  程序做了什么：                                                                  │
│  ├── 加载 best_model.ckpt（验证集上表现最好的那个模型）                          │
│  ├── 用这个模型在【测试集】上做预测                                              │
│  ├── 计算 test_auc 和 test_aupr                                                 │
│  └── 输出："最终AUC = 0.8521"  ← 这个数字写进论文！                              │
│                                                                                 │
│  测试阶段的流程（和验证阶段一样，只是用的是测试集）：                             │
│  for batch in 测试集:                                                           │
│      predictions = model(batch)                                                 │
│      记录predictions和labels                                                    │
│  test_auc = 计算AUC(all_predictions, all_labels)                                │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 0.3 各概念的调用时机总结

| 概念 | 什么时候被调用？ | 调用频率 | 作用 |
|------|-----------------|---------|------|
| **训练集** | 每轮Epoch的训练阶段 | 每轮都用，可重复 | 让模型学习规律 |
| **验证集** | 每轮Epoch结束时 | 每轮都用，可重复 | 检查学习效果，挑选最佳模型 |
| **测试集** | 全部训练结束后 | **只用一次！** | 最终评估，结果写进论文 |
| **Epoch** | 整个训练期间 | 循环多轮（如45轮） | 把训练集完整过一遍 |
| **Batch** | 每轮Epoch内 | 每轮约13,746次 | 每次处理32条数据 |
| **损失函数** | 训练阶段的每个Batch | 每个Batch计算一次 | 衡量预测有多"错" |
| **Adam优化器** | 训练阶段的每个Batch | 每次参数更新时使用 | "智能老师"，决定怎么调参数 |
| **学习率** | 训练阶段的每个Batch | 每次参数更新时使用 | 控制参数更新幅度（步子大小） |
| **Warmup** | 训练最初几轮 | 前N轮（如前5轮） | 热身期，学习率从小到大 |
| **学习率调度器** | 每轮Epoch的验证阶段后 | 每轮检查一次 | 学习停滞时自动降低学习率 |
| **早停** | 每轮Epoch的验证阶段后 | 每轮检查一次 | 防止过拟合，提前结束训练 |
| **AUC/AUPR** | 验证和测试阶段 | 每轮验证+最终测试 | 评估模型好不好 |

---

## 0.4 嵌套关系图解

```
整个训练过程
│
├─→ Epoch 1
│   ├─→ 训练阶段（用训练集）
│   │   ├─→ Batch 1     → 预测 → 损失 → 更新参数
│   │   ├─→ Batch 2     → 预测 → 损失 → 更新参数
│   │   ├─→ Batch 3     → 预测 → 损失 → 更新参数
│   │   ├─→ ...
│   │   └─→ Batch 13746 → 预测 → 损失 → 更新参数
│   │
│   └─→ 验证阶段（用验证集，不更新参数）
│       ├─→ 对验证集所有数据做预测
│       ├─→ 计算 val_auc
│       └─→ 决定：保存模型？早停？
│
├─→ Epoch 2
│   ├─→ 训练阶段...
│   └─→ 验证阶段...
│
├─→ ...
│
├─→ Epoch 45（假设这轮val_auc最高）
│   ├─→ 训练阶段...
│   └─→ 验证阶段 → val_auc=0.8521 → 保存模型！
│
├─→ Epoch 46-65（val_auc不再提升）
│   └─→ ...
│
├─→ Epoch 65 → 早停触发！退出训练循环
│
└─→ 最终测试阶段（只执行一次！）
    ├─→ 加载第45轮保存的模型
    ├─→ 用测试集评估
    └─→ 报告：test_auc = 0.8521
```

---

## 0.5 一个具体的数字例子

假设EZSpecificity训练了45轮就早停了，下面是完整的计算：

| 阶段 | 计算 |
|------|------|
| **总Epoch数** | 45轮（第65轮早停） |
| **每轮训练阶段Batch数** | 439,887 ÷ 32 ≈ 13,746次 |
| **每轮验证阶段Batch数** | 43,988 ÷ 32 ≈ 1,375次 |
| **总共处理了多少次Batch** | 45 × (13,746 + 1,375) = 680,445次 |
| **损失函数被计算了多少次** | 45 × 13,746 = 618,570次（只在训练阶段计算） |
| **参数被更新了多少次** | 45 × 13,746 = 618,570次 |
| **验证集被完整遍历了多少次** | 45次 |
| **测试集被使用了多少次** | **1次**（最后才用！） |

---

## 0.6 为什么要这样设计？（逻辑链条）

```
问题1：为什么要用Batch，不能一次看全部数据吗？
答：全部数据太大（几十GB），显存放不下。分成小批次处理是必须的。

问题2：为什么每个Batch都要计算损失和更新参数？
答：这样可以快速学习。如果等看完全部数据再更新，每轮只能学一次，太慢了。

问题3：为什么要多轮Epoch？
答：一遍看不会。就像读书要读很多遍才能记住一样。

问题4：为什么每轮要用验证集检查？
答：为了知道"学到哪了"。训练集上表现好不代表真的学会了，要用新数据检查。

问题5：为什么验证集不更新参数？
答：如果更新，验证集就变成训练集了，就不能客观检查效果了。

问题6：为什么测试集只能用一次？
答：如果反复用测试集调整模型，测试集就被"污染"了，最终分数不可信。

问题7：为什么要早停？
答：训练太多轮会"背答案"（过拟合）。当验证集不再进步时，说明开始背答案了，应该停止。

问题8：为什么保存的是验证集最好的模型，而不是最后一个？
答：最后一个模型可能已经过拟合了。验证集最好的那个才是泛化能力最强的。
```

---

## 0.7 快速参考卡片

如果你只想记住最核心的内容，看这张卡片：

```
┌─────────────────────────────────────────────────────────────────┐
│                    训练流程速查卡                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. 整个训练 = 多轮Epoch                                         │
│     └─ 每轮Epoch = 训练阶段 + 验证阶段                           │
│         └─ 训练阶段 = 多个Batch                                  │
│             └─ 每个Batch = 预测 → 算损失 → Adam更新参数           │
│                                                                 │
│  2. 训练集：每轮Epoch的训练阶段用，用来学习                       │
│  3. 验证集：每轮Epoch结束时用，用来检查进度                       │
│  4. 测试集：全部结束后用一次，用来报告最终成绩                    │
│                                                                 │
│  5. 损失函数：每个Batch计算一次，告诉模型预测有多错               │
│  6. Adam优化器：每个Batch调用，"智能老师"帮你调参数              │
│  7. 学习率：每次更新参数时用，控制学多快（步子大小）              │
│  8. Warmup：前几轮学习率从小到大，像运动前热身                    │
│  9. 学习率调度器：学习停滞时自动把学习率减半                      │
│  10. 早停：验证集不进步时触发，防止背答案                         │
│                                                                 │
│  关键时间节点：                                                  │
│  ├─ 训练开始前：加载3个数据集 + 创建Adam优化器                   │
│  ├─ 前几轮Epoch：Warmup热身期，学习率逐渐增大                    │
│  ├─ 每个Batch：计算损失 → Adam优化器更新参数                     │
│  ├─ 每轮Epoch结束：用验证集评估 → 决定是否保存/早停/降学习率     │
│  └─ 训练结束后：用测试集评估一次 → 报告结果                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

<a name="第一章"></a>
# 第一章：从一个生活例子开始

## 1.1 考驾照的故事

想象你要考驾照，驾校给了你一本题库，里面有1000道题。

### 方案A（错误方法）

```
你的做法：
1. 把1000道题全部做一遍，记住答案
2. 考试时，考的就是这1000道题中的100道
3. 你得了100分！

问题：
- 你真的学会了交通规则吗？
- 还是只是"背答案"？
- 如果考试出了第1001道新题，你还会吗？
```

**这叫"过拟合"** —— 模型只是记住了答案，没有真正学会规律。

### 方案B（正确方法）

```
你的做法：
1. 把1000道题分成两部分：
   - 800道用来练习（可以看答案）
   - 200道留着模拟考试（不能提前看答案）
2. 用800道题练习，学会交通规则
3. 用200道题测试自己，看看真正学会了多少

结果：
- 练习时正确率：95%（因为可以看答案）
- 模拟考试正确率：82%（因为是"新题"）
- 82%才是你真正的水平！
```

**这就是为什么需要"测试集"** —— 用模型没见过的数据来评估真实能力。

---

## 1.2 但是，有个新问题...

假设你有10种不同的学习方法：
- 方法1：死记硬背
- 方法2：画思维导图
- 方法3：做错题本
- ...

你想知道哪种方法最好。

### 错误做法

```
你的做法：
1. 用方法1练习800道题 → 用200道测试 → 得分82分
2. 用方法2练习800道题 → 用同样200道测试 → 得分85分
3. 用方法3练习800道题 → 用同样200道测试 → 得分88分
...
10. 选择得分最高的方法

问题：
- 你用测试题"挑选"了最好的方法
- 相当于测试题也被"用掉"了
- 最终报告的88分可能偏高！
```

### 正确做法：三分数据

```
把1000道题分成三份：
┌─────────────────────────────────────────────────────────┐
│  练习题（训练集）    │  模拟考（验证集）  │  期末考（测试集）│
│      600道          │      200道        │      200道       │
│  用来学习规则        │  用来挑选方法      │  最终评估        │
│  可以反复做          │  可以多次测试      │  只能用一次！    │
└─────────────────────────────────────────────────────────┘

流程：
1. 用600道练习，用200道模拟考，挑出最好的方法
2. 确定方法后，用最后200道"期末考"评估真实水平
3. 期末考的分数才是最终报告的分数
```

---

<a name="第二章"></a>
# 第二章：机器学习训练的本质是什么？

## 2.1 什么是"训练"？

**训练 = 让机器通过大量例子学会规律**

### 人类学习 vs 机器学习

| 步骤 | 人类学驾照 | 机器学习（EZSpecificity） |
|------|-----------|--------------------------|
| **输入** | 看题目（交通标志图片） | 看数据（酶的序列 + 底物的结构） |
| **目标** | 选出正确答案 | 预测"这个酶能不能催化这个底物" |
| **学习方式** | 看解析，记住规律 | 调整内部参数，让预测越来越准 |
| **检验方式** | 做模拟题 | 用验证集测试准确率 |

## 2.2 训练的具体过程（用EZSpecificity举例）

### 一条训练数据长什么样？

```
┌─────────────────────────────────────────────────────────────┐
│                     一条训练数据                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  输入1：酶的信息                                             │
│  ├── UniProt ID: P00183                                     │
│  ├── 氨基酸序列: MTIKEMPQPKTFGELKNLPL... (414个字母)         │
│  └── 来自ESM-2模型的特征向量 (1280维)                        │
│                                                             │
│  输入2：底物的信息                                           │
│  ├── 反应ID: 12345                                          │
│  ├── SMILES: CC(C)C1=CC=C(C=C1)C(C)C(=O)O                   │
│  └── 来自GROVER模型的特征向量 (5000维)                       │
│                                                             │
│  标签（答案）：                                              │
│  └── label = 1 （表示：这个酶能催化这个底物）                 │
│      或                                                     │
│      label = 0 （表示：这个酶不能催化这个底物）               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 训练一轮（One Epoch）发生了什么？

```python
# 伪代码：一轮训练的过程

# 假设训练集有439,887条数据，每次处理32条（batch_size=32）
# 那么一轮需要处理 439,887 ÷ 32 ≈ 13,746 次

for batch in 训练集:  # 循环13,746次

    # 第1步：模型做预测
    # 模型看到32对(酶, 底物)，猜测每对能不能反应
    预测结果 = 模型(batch中的酶, batch中的底物)
    # 预测结果是32个0到1之间的数字
    # 比如 [0.8, 0.2, 0.9, 0.1, ...]
    # 0.8 表示模型"比较确定"能反应
    # 0.2 表示模型"比较确定"不能反应

    # 第2步：计算损失（模型错得有多离谱）
    真实答案 = batch中的label  # 比如 [1, 0, 1, 0, ...]
    损失 = 计算差距(预测结果, 真实答案)
    # 如果预测[0.8, 0.2, 0.9, 0.1]，真实[1, 0, 1, 0]
    # 损失很小，因为预测得很准
    # 如果预测[0.2, 0.8, 0.1, 0.9]，真实[1, 0, 1, 0]
    # 损失很大，因为完全预测反了

    # 第3步：调整模型参数
    # 这是"学习"的核心！
    # 模型内部有几百万个参数（数字）
    # 根据损失，微调这些参数，让下次预测更准
    optimizer.step()  # 这行代码执行参数更新

# 一轮结束后，模型已经"看过"了全部439,887条数据
# 然后开始下一轮，再看一遍...
```

### 为什么要训练很多轮（Epoch）？

| 轮数 | 类比 | 效果 |
|------|------|------|
| 第1轮 | 第一遍读课本 | 模型初步了解规律，但记不住 |
| 第10轮 | 读了10遍 | 开始记住一些模式 |
| 第50轮 | 读了50遍 | 记住了大部分规律 |
| 第100轮 | 读了100遍 | 可能开始"死记硬背"了（过拟合） |

**关键问题**：训练多少轮最好？太少学不会，太多会"死记硬背"。

**答案**：用验证集来决定！

---

<a name="第三章"></a>
# 第三章：为什么需要训练集、验证集、测试集？

## 3.1 三种数据集的角色

```
┌─────────────────────────────────────────────────────────────────────┐
│                        数据集的三种角色                              │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│   ┌─────────────────────────────────────────────────────────────┐   │
│   │                    训练集 (Training Set)                     │   │
│   │                       439,887 条                             │   │
│   │                                                             │   │
│   │   角色：教科书                                                │   │
│   │   用途：模型从这些数据中学习规律                               │   │
│   │   特点：模型可以反复看，可以看答案                             │   │
│   │                                                             │   │
│   │   类比：学生平时做的练习题，可以对答案、可以重做               │   │
│   └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│   ┌─────────────────────────────────────────────────────────────┐   │
│   │                    验证集 (Validation Set)                   │   │
│   │                        43,988 条                             │   │
│   │                                                             │   │
│   │   角色：模拟考试                                              │   │
│   │   用途：                                                     │   │
│   │   1. 监控训练进度（学得怎么样了？）                           │   │
│   │   2. 挑选最佳模型（哪个版本最好？）                           │   │
│   │   3. 调整超参数（学习速度多快合适？）                         │   │
│   │   特点：模型不能看答案，但可以多次测试                        │   │
│   │                                                             │   │
│   │   类比：每周的小测验，用来检查学习进度                        │   │
│   └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│   ┌─────────────────────────────────────────────────────────────┐   │
│   │                     测试集 (Test Set)                        │   │
│   │                       102,640 条                             │   │
│   │                                                             │   │
│   │   角色：期末考试 / 高考                                       │   │
│   │   用途：最终评估模型的真实能力                                │   │
│   │   特点：                                                     │   │
│   │   - 模型从未见过这些数据                                     │   │
│   │   - 只能用一次！                                             │   │
│   │   - 这个分数才是论文里报告的分数                             │   │
│   │                                                             │   │
│   │   类比：高考，一锤定音，不能重来                             │   │
│   └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

## 3.2 验证集的核心作用：Early Stopping（早停）

### 问题：训练多少轮最好？

```
训练轮数 vs 准确率的关系（示意图）

准确率
  │
  │                    ╭──────────────  训练集准确率（一直上升）
  │                 ╭──╯
  │              ╭──╯
  │           ╭──╯        ╭────╮
  │        ╭──╯      ╭────╯    ╰────  验证集准确率（先升后降）
  │     ╭──╯    ╭────╯
  │  ╭──╯  ╭────╯
  │──╯╭────╯
  ├───┴────┴────┬────┬────┬────┬────┬────→ 训练轮数
  0            20   40   60   80  100

         最佳点 ↑
    （验证集准确率最高的地方）
```

### 解读这张图

| 区域 | 训练集表现 | 验证集表现 | 状态 |
|------|-----------|-----------|------|
| 0-40轮 | 逐渐上升 | 逐渐上升 | **正常学习**：模型在学规律 |
| 40-60轮 | 继续上升 | 开始下降 | **过拟合开始**：模型开始背答案 |
| 60-100轮 | 接近100% | 持续下降 | **严重过拟合**：只会做见过的题 |

### Early Stopping 策略

```python
# 伪代码：Early Stopping

最佳验证准确率 = 0
最佳模型 = None
耐心计数器 = 0
最大耐心 = 10  # 如果10轮都没有进步，就停止

for epoch in range(100):  # 最多训练100轮

    # 训练一轮
    在训练集上训练模型()

    # 用验证集检查效果
    当前验证准确率 = 在验证集上测试()

    if 当前验证准确率 > 最佳验证准确率:
        # 有进步！保存当前模型
        最佳验证准确率 = 当前验证准确率
        最佳模型 = 复制当前模型()
        耐心计数器 = 0  # 重置耐心
        print(f"第{epoch}轮：新的最佳！准确率={当前验证准确率}")
    else:
        # 没有进步
        耐心计数器 += 1
        print(f"第{epoch}轮：没有进步，耐心剩余{最大耐心-耐心计数器}轮")

    if 耐心计数器 >= 最大耐心:
        print("连续10轮没有进步，停止训练！")
        break

# 训练结束后，使用最佳模型，而不是最后一个模型
最终模型 = 最佳模型
```

### 为什么验证集准确率会下降？

```
┌─────────────────────────────────────────────────────────────────┐
│                        过拟合的本质                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   想象你在学"判断动物是不是猫"：                                 │
│                                                                 │
│   训练数据只有3张猫的照片：                                      │
│   - 照片1：橘猫，坐着                                           │
│   - 照片2：橘猫，躺着                                           │
│   - 照片3：橘猫，站着                                           │
│                                                                 │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │ 正确学习：                                               │   │
│   │ "有尖耳朵、胡须、毛茸茸的四脚动物是猫"                    │   │
│   │  → 看到黑猫也能认出是猫 ✓                                │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │ 过拟合学习：                                             │   │
│   │ "橘色的、毛茸茸的东西是猫"                                │   │
│   │  → 看到黑猫认不出是猫 ✗                                  │   │
│   │  → 看到橘色毛绒玩具认为是猫 ✗                            │   │
│   └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│   过拟合 = 模型记住了训练数据的"特殊细节"，而不是"通用规律"      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

<a name="第四章"></a>
# 第四章：什么是Fold（交叉验证）？

## 4.1 为什么需要Fold？

### 问题：运气的影响

假设你只做一次实验：

```
全部数据（586,515条）
         │
    随机分成3份
         │
    ┌────┴────┐
训练集   验证集   测试集

问题：
- 万一测试集里恰好都是"简单"的数据呢？→ 分数偏高
- 万一测试集里恰好都是"困难"的数据呢？→ 分数偏低
- 一次实验的结果可能是"运气好/差"，不够可靠
```

### 解决方案：多做几次，取平均

```
做4次实验，每次用不同的数据划分，最后取平均分数

这就是 4-Fold 交叉验证！
```

## 4.2 Fold的具体划分方式

### 图解4-Fold交叉验证

```
全部数据（586,515条）平均分成4份：
┌─────────┬─────────┬─────────┬─────────┐
│  Part A │  Part B │  Part C │  Part D │
│ ~147k   │ ~147k   │ ~147k   │ ~147k   │
└─────────┴─────────┴─────────┴─────────┘

════════════════════════════════════════════════════════════════

Fold 0（第一种划分方式）：
┌─────────┬─────────┬─────────┬─────────┐
│  测试集  │←────── 训练集 + 验证集 ──────→│
│  Part A │  Part B │  Part C │  Part D │
│ 102,640 │              439,887 + 43,988 │
└─────────┴─────────┴─────────┴─────────┘
训练一个模型 → 测试准确率 = 85.2%

════════════════════════════════════════════════════════════════

Fold 1（第二种划分方式）：
┌─────────┬─────────┬─────────┬─────────┐
│←─训练─→│  测试集  │←───── 训练 + 验证 ────→│
│  Part A │  Part B │  Part C │  Part D │
└─────────┴─────────┴─────────┴─────────┘
训练另一个模型 → 测试准确率 = 84.8%

════════════════════════════════════════════════════════════════

Fold 2（第三种划分方式）：
┌─────────┬─────────┬─────────┬─────────┐
│←───── 训练 + 验证 ────→│  测试集  │←─训练─→│
│  Part A │  Part B │  Part C │  Part D │
└─────────┴─────────┴─────────┴─────────┘
训练另一个模型 → 测试准确率 = 85.5%

════════════════════════════════════════════════════════════════

Fold 3（第四种划分方式）：
┌─────────┬─────────┬─────────┬─────────┐
│←────── 训练集 + 验证集 ──────→│  测试集  │
│  Part A │  Part B │  Part C │  Part D │
└─────────┴─────────┴─────────┴─────────┘
训练另一个模型 → 测试准确率 = 84.9%

════════════════════════════════════════════════════════════════

最终结果：
平均准确率 = (85.2 + 84.8 + 85.5 + 84.9) / 4 = 85.1%
标准差 = 0.3%

论文报告：准确率 85.1% ± 0.3%
```

## 4.3 回答你的关键问题

### Q1: 一个Fold是否包含全部数据？

**是的！每个Fold都使用了全部586,515条数据！**

```
Fold 0: Part A(测试) + Part B(训练) + Part C(训练) + Part D(训练/验证) = 全部
Fold 1: Part A(训练) + Part B(测试) + Part C(训练) + Part D(训练/验证) = 全部
Fold 2: Part A(训练) + Part B(训练) + Part C(测试) + Part D(训练/验证) = 全部
Fold 3: Part A(训练) + Part B(训练) + Part C(训练) + Part D(测试)      = 全部
```

每个Fold只是**角色分配不同**，不是数据子集！

### Q2: 为什么EZSpecificity只用了Fold 0？

根据项目文件，EZSpecificity的发布模型（run_0）只使用了Fold 0进行训练。

可能的原因：
1. **时间成本**：训练一个模型可能需要几天，训练4个太慢
2. **资源限制**：GPU资源有限
3. **足够可靠**：单个Fold的结果已经足够好

但在严格的科学研究中，通常会跑完所有Fold并报告平均值。

### Q3: 数据是怎么分到各个Fold的？

```python
# 简化的划分逻辑

import pandas as pd
import numpy as np

# 读取全部数据
data = pd.read_csv('data.csv')  # 586,515 条

# 随机打乱
data = data.sample(frac=1, random_state=42).reset_index(drop=True)

# 分成4份
n = len(data)  # 586,515
fold_size = n // 4  # 约 146,628

folds = {
    0: data[0:fold_size],              # Part A
    1: data[fold_size:2*fold_size],    # Part B
    2: data[2*fold_size:3*fold_size],  # Part C
    3: data[3*fold_size:]              # Part D
}

# 生成Fold 0的数据文件
test_data_0 = folds[0]                          # Part A 作为测试集
train_data_0 = pd.concat([folds[1], folds[2]])  # Part B + C 作为训练集
val_data_0 = folds[3]                           # Part D 作为验证集

# 保存
test_data_0.to_csv('testing_datas_0.csv')
train_data_0.to_csv('training_datas_0.csv')
val_data_0.to_csv('val_datas_0.csv')
```

---

<a name="第五章"></a>
# 第五章：EZSpecificity的真实训练过程

## 5.1 训练的完整流程图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    EZSpecificity 训练完整流程                           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│   【第1步：准备数据】                                                    │
│   ├── 读取训练集: training_datas_0.csv (439,887条)                      │
│   ├── 读取验证集: val_datas_0.csv (43,988条)                            │
│   └── 读取测试集: testing_datas_0.csv (102,640条)                       │
│                          │                                              │
│                          ▼                                              │
│   【第2步：初始化模型】                                                  │
│   ├── 创建神经网络结构                                                  │
│   ├── 随机初始化几百万个参数                                            │
│   └── 此时模型什么都不会，预测相当于瞎猜                                │
│                          │                                              │
│                          ▼                                              │
│   【第3步：训练循环】                                                    │
│   ┌──────────────────────────────────────────────────────────────┐     │
│   │  for epoch in range(max_epochs):  # 比如100轮                 │     │
│   │      │                                                        │     │
│   │      ├── 3.1 在训练集上学习                                   │     │
│   │      │   for batch in training_dataloader:                    │     │
│   │      │       预测 = model(酶特征, 底物特征)                    │     │
│   │      │       损失 = 计算(预测 vs 真实标签)                     │     │
│   │      │       optimizer.step()  # 更新参数                     │     │
│   │      │                                                        │     │
│   │      ├── 3.2 在验证集上评估                                   │     │
│   │      │   验证准确率 = evaluate(model, val_dataloader)         │     │
│   │      │                                                        │     │
│   │      ├── 3.3 决定是否保存模型                                 │     │
│   │      │   if 验证准确率 > 历史最佳:                            │     │
│   │      │       保存模型到 best_model.ckpt                       │     │
│   │      │       更新历史最佳                                     │     │
│   │      │                                                        │     │
│   │      └── 3.4 决定是否早停                                     │     │
│   │          if 连续N轮没有进步:                                  │     │
│   │              break                                            │     │
│   └──────────────────────────────────────────────────────────────┘     │
│                          │                                              │
│                          ▼                                              │
│   【第4步：最终评估】                                                    │
│   ├── 加载 best_model.ckpt（验证集上表现最好的那个版本）                │
│   ├── 在测试集上评估: test_accuracy = evaluate(model, test_dataloader) │
│   └── 报告结果: "模型准确率 = XX%"                                      │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

## 5.2 EZSpecificity的真实代码解析

### 数据加载（src/Datasets/brenda.py）

```python
# 文件: src/Datasets/brenda.py

class Singledataset(pl.LightningDataModule):
    def __init__(self, config):
        super().__init__()

        # 从配置文件读取数据路径
        # config.data.train_data_path = "ESIBank/brenda/random_split/training_datas_0.csv"
        # config.data.val_data_path = "ESIBank/brenda/random_split/val_datas_0.csv"
        # config.data.test_data_path = "ESIBank/brenda/random_split/testing_datas_0.csv"

        self.train_df = read_datasets(config.data.train_data_path)  # 439,887条
        self.val_df = read_datasets(config.data.val_data_path)      # 43,988条
        self.test_df = read_datasets(config.data.test_data_path)    # 102,640条

    def train_dataloader(self):
        # 把训练数据转换成模型能读取的格式
        # batch_size=32 意味着每次给模型看32条数据
        return DataLoader(data, batch_size=32, shuffle=True)  # shuffle=True 打乱顺序

    def val_dataloader(self):
        return DataLoader(data, batch_size=32, shuffle=False)  # shuffle=False 保持顺序

    def test_dataloader(self):
        return DataLoader(data, batch_size=32, shuffle=False)
```

**代码解读**：
- `train_dataloader`: 训练时调用，数据被打乱（shuffle=True），防止模型记住顺序
- `val_dataloader`: 验证时调用，不打乱
- `test_dataloader`: 测试时调用，不打乱

### 模型训练（src/Models/ss.py）

```python
# 文件: src/Models/ss.py

class SS(pl.LightningModule):
    """SS = Substrate Specificity（底物特异性）模型"""

    def training_step(self, batch, batch_idx):
        """
        每处理一个batch调用一次
        batch: 包含32对(酶, 底物)的数据
        """
        # 1. 模型做预测
        logits, tag = self(batch)  # self(batch) 调用 forward() 方法
        # logits: 形状[32, 1]，每个值是0-1之间的预测概率

        # 2. 计算损失
        loss = self.get_loss(batch, logits, "train")
        # 损失是一个数字，表示预测有多"错"
        # 损失越小，预测越准

        return loss  # PyTorch Lightning 会自动用这个loss更新参数

    def get_loss(self, x, logits, stage):
        """计算损失函数"""
        logits = logits.squeeze(-1)  # [32, 1] → [32]

        # BCEWithLogitsLoss: 二分类交叉熵损失
        # 预测越接近真实标签，损失越小
        loss = torch.nn.BCEWithLogitsLoss()(logits, x.label)

        self.log(f"sp_loss/{stage}", loss)  # 记录日志
        return loss

    def validation_step(self, batch, batch_idx):
        """验证时调用，不更新参数，只评估"""
        return self.evaluate(batch, 'val')

    def test_step(self, batch, batch_idx):
        """测试时调用"""
        return self.evaluate(batch, 'test')

    def configure_optimizers(self):
        """配置优化器（决定怎么更新参数）"""
        # Adam: 一种常用的优化算法
        # lr=0.001: 学习率，决定每次更新参数的幅度
        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)

        # ReduceLROnPlateau: 如果验证集准确率停滞，就降低学习率
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode='max',      # 目标是最大化指标
            patience=10,     # 如果10轮没进步，就降低学习率
            factor=0.5       # 学习率变为原来的一半
        )

        return [optimizer], [scheduler]
```

### 评估指标（AUC和AUPR）

```python
def get_auc_aupr(self, logits, label, name, stage):
    """
    计算AUC和AUPR评估指标

    logits: 模型的预测概率 [0.8, 0.2, 0.9, ...]
    label:  真实标签 [1, 0, 1, ...]
    """
    from sklearn import metrics

    # AUC (Area Under ROC Curve): ROC曲线下面积
    # 0.5 = 随机猜（最差）
    # 1.0 = 完美预测（最好）
    fpr, tpr, _ = metrics.roc_curve(label, logits)
    auc = metrics.auc(fpr, tpr)

    # AUPR (Area Under Precision-Recall Curve): 精确率-召回率曲线下面积
    aupr = metrics.average_precision_score(label, logits)

    print(f"auc/{stage}: {auc}")   # 比如 "auc/val: 0.85"
    print(f"aupr/{stage}: {aupr}") # 比如 "aupr/val: 0.78"

    return auc, aupr
```

**指标解读**：

| 指标 | 含义 | 范围 | 好的标准 |
|------|------|------|---------|
| **AUC** | 模型区分正负样本的能力 | 0.5-1.0 | >0.8 较好，>0.9 很好 |
| **AUPR** | 在正样本较少时的表现 | 0-1.0 | 越高越好 |

---

<a name="第六章"></a>
# 第六章：实际训练组件详解（v4.0 通俗版）

> **本章目的**：用最通俗的语言讲解EZSpecificity代码中实际使用的训练组件
> **阅读前提**：已经理解了第零章的训练流程时间线
> **核心思想**：每个组件都是训练流程中的一个"角色"，各司其职

---

## 6.1 优化器（Optimizer）—— 模型的"智能老师"

### 用一句话说清楚

**优化器 = 决定"怎么学习"的老师**

就像学习可以有不同的方法（死记硬背、理解记忆、联想记忆...），模型学习也可以有不同的"学习方法"。优化器就是这个学习方法。

### 生活类比：找山谷底部

```
想象你蒙着眼睛站在一座山上，目标是走到山谷最低点（损失最小）。

┌─────────────────────────────────────────────────────────────────┐
│                          山顶 (损失大)                           │
│                              ╱╲                                 │
│                            ╱    ╲                               │
│                          ╱   你   ╲                             │
│                        ╱     ↓     ╲                            │
│                      ╱       ↓       ╲                          │
│                    ╱    怎么走？       ╲                        │
│                  ╱           ↓           ╲                      │
│                ╱_____________↓_____________╲ 山谷底部 (损失最小)   │
│                                                                 │
│   问题1：往哪个方向走？→ 这由"梯度"告诉你（哪边更低就往哪走）     │
│   问题2：每步走多远？  → 这由"学习率"决定                        │
│   问题3：用什么策略走？→ 这由"优化器"决定                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 不同优化器 = 不同的"走路策略"

| 优化器 | 走路策略 | 大白话解释 | EZSpecificity用吗？ |
|--------|----------|------------|-------------------|
| **Adam** | 智能变速 | 根据历史经验，有的参数大步走，有的参数小步走 | **是（默认）** |
| SGD | 固定步伐 | 每一步都走一样的距离，很稳但很慢 | 否 |
| RMSprop | 防抖动 | 专门解决"走来走去原地打转"的问题 | 否 |
| AdamW | Adam升级版 | Adam + 额外的"减肥机制"防止模型变臃肿 | 否 |

### Adam为什么是"智能"老师？

```
┌─────────────────────────────────────────────────────────────────┐
│                   Adam的"智能"体现在哪里？                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   假设模型有两个参数需要调整：参数A 和 参数B                      │
│                                                                 │
│   场景：                                                        │
│   ├── 参数A：每次变化都很大，上蹿下跳                            │
│   └── 参数B：一直没怎么变化，很稳定                              │
│                                                                 │
│   普通老师（SGD）的做法：                                        │
│   └── "两个参数都走0.001步！" → 一视同仁，效率低                 │
│                                                                 │
│   智能老师（Adam）的做法：                                       │
│   ├── 对参数A："你太活跃了，给你踩刹车，走0.0001步"             │
│   └── 对参数B："你太安静了，给你加油门，走0.01步"                │
│                                                                 │
│   结果：Adam能更快地找到最优解！                                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 在EZSpecificity代码中长什么样？

代码位置：[ss.py:240-250](src/Models/ss.py#L240-L250)

```python
# 创建Adam优化器
optimizer = torch.optim.Adam(
    self.parameters(),    # 要优化哪些参数？→ 模型的所有参数（几百万个）
    lr=0.001              # 基础学习率是多少？→ 0.001
)
# 就这一行！Adam会自动帮你智能调整每个参数的学习步长
```

---

## 6.2 学习率调度器（LR Scheduler）—— "自动挡"的学习速度

### 用一句话说清楚

**学习率调度器 = 自动调整学习快慢的"自动挡"**

开车时，起步用1挡，加速用2、3挡，高速用5挡。学习也一样：开始可以学快点，后期要慢下来精细打磨。

### 生活类比：学骑自行车

```
┌─────────────────────────────────────────────────────────────────┐
│                   学骑自行车的过程                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   第1天：完全不会，需要大胆尝试                                   │
│   └── 学习率高（lr=0.001）：大胆调整，快速进步                    │
│                                                                 │
│   第10天：基本会骑了，但还不稳                                    │
│   └── 学习率保持：继续稳步提升                                   │
│                                                                 │
│   第20天：骑得挺好了，但进步变慢了                                │
│   └── 问题来了！用同样的方法练习，没啥进步了                      │
│                                                                 │
│   这时候需要：换一种练习方式！                                   │
│   ├── 之前：大开大合地练习（学习率大）                           │
│   └── 现在：精细调整姿势（学习率小）                             │
│                                                                 │
│   学习率调度器的作用：                                           │
│   "检测到你进步停滞了，自动帮你把学习率减半！"                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### EZSpecificity用的调度器：ReduceLROnPlateau

**中文名：进步停滞时自动减速**

```
工作原理（超级简单版）：

┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│   监控目标：验证集的AUC分数                                       │
│                                                                 │
│   规则：                                                        │
│   ├── 如果AUC在提升 → 保持当前学习率，继续学                      │
│   └── 如果AUC连续10轮不提升 → 学习率减半！                        │
│                                                                 │
│   实际例子：                                                     │
│   ├── Epoch 1-15：AUC从0.6涨到0.8，lr=0.001，不变                │
│   ├── Epoch 16-25：AUC一直在0.8附近晃，没进步                     │
│   │   └── 调度器："等了10轮了，减速！lr变成0.0005"                │
│   ├── Epoch 26-30：AUC从0.8涨到0.82，又进步了！                   │
│   ├── Epoch 31-40：AUC又停滞了                                   │
│   │   └── 调度器："再减速！lr变成0.00025"                        │
│   └── ...直到lr降到最低值0.000001就不再降了                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 为什么这样设计？

```
学习率太大的问题：
┌─────────────────────────────────────────────────────────────────┐
│   最优解在这里 → ★                                              │
│                                                                 │
│   学习率太大时，参数更新太猛：                                    │
│       ←────────────→                                            │
│   "跳来跳去，总是跳过最优点！"                                   │
└─────────────────────────────────────────────────────────────────┘

学习率变小后：
┌─────────────────────────────────────────────────────────────────┐
│   最优解在这里 → ★                                              │
│                                                                 │
│   学习率变小，参数更新变温和：                                    │
│           →→→→★                                                 │
│   "小碎步慢慢靠近，稳稳落在最优点！"                              │
└─────────────────────────────────────────────────────────────────┘
```

### 在EZSpecificity代码中长什么样？

代码位置：[ss.py:252-256](src/Models/ss.py#L252-L256)

```python
# 创建学习率调度器
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='max',       # 监控的指标要"最大化"（AUC越大越好）
    factor=0.5,       # 每次减半（0.001 → 0.0005 → 0.00025）
    patience=10,      # 等10轮不进步才减速
    min_lr=0.000001   # 最低不能低于这个值
)
```

---

## 6.3 Warmup策略 —— 训练前的"热身运动"

### 用一句话说清楚

**Warmup = 训练最开始时，学习率从小到大逐渐增加**

就像运动员比赛前要热身一样，模型训练前也需要"热身"。

### 生活类比：冬天启动汽车

```
┌─────────────────────────────────────────────────────────────────┐
│                   冬天启动汽车 vs 模型训练                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   【冬天启动汽车】                                               │
│   ├── 刚启动时：发动机冷，机油还没润滑好                          │
│   ├── 如果立刻大油门：容易损坏发动机！                            │
│   └── 正确做法：先怠速热车几分钟，再慢慢加速                       │
│                                                                 │
│   【模型训练】                                                   │
│   ├── 刚开始时：参数是随机的，梯度很不稳定                        │
│   ├── 如果立刻用大学习率：参数可能"爆炸"，训练失败！              │
│   └── 正确做法：先用小学习率"热身"，再逐渐提高到正常学习率        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 学习率变化过程图解

```
学习率
  │
  │                            ╭────────── 正常学习阶段 (lr=0.001)
  │                      ╭─────╯
  │                 ╭────╯
  │            ╭────╯
  │       ╭────╯
  │  ╭────╯      ↑
  │──╯           │
  ├──────────────┴─────────────────────────────────────→ Epoch
  0     Warmup阶段        正常训练阶段
        (比如前5轮)

  Epoch 1: lr = 0.0002  ← 先用很小的学习率
  Epoch 2: lr = 0.0004  ← 逐渐增加
  Epoch 3: lr = 0.0006
  Epoch 4: lr = 0.0008
  Epoch 5: lr = 0.001   ← 达到正常学习率
  Epoch 6+: lr = 0.001  ← 保持正常学习率
```

### 为什么不直接用大学习率？

```
┌─────────────────────────────────────────────────────────────────┐
│               没有Warmup会发生什么？                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   训练开始时：                                                  │
│   ├── 模型参数是随机初始化的（乱七八糟的数字）                    │
│   ├── 这些随机参数产生的梯度也是乱七八糟的                        │
│   └── 梯度的方向和大小都很不靠谱                                 │
│                                                                 │
│   如果用大学习率（lr=0.001）：                                   │
│   ├── 大学习率 × 乱七八糟的梯度 = 参数更新得很猛                  │
│   ├── 可能把参数更新到一个很差的位置                              │
│   └── 严重时：参数变成 NaN（无穷大），训练直接崩溃！              │
│                                                                 │
│   如果先用小学习率热身：                                         │
│   ├── 小学习率 × 乱七八糟的梯度 = 参数只更新一点点                │
│   ├── 几轮后，参数变得稳定，梯度也变得靠谱了                      │
│   └── 这时候再用大学习率，就很安全了                             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 在EZSpecificity代码中长什么样？

代码位置：[ss.py:268-277](src/Models/ss.py#L268-L277)

```python
def optimizer_step(self, epoch, ...):
    # 如果还在warmup阶段（比如前5轮）
    if epoch < warmup_epochs:  # warmup_epochs = 5
        # 计算当前应该用的学习率
        # 从 min_lr(0.000001) 线性增加到 lr(0.001)
        warmup_lr = min_lr + (epoch / warmup_epochs) * (lr - min_lr)

        # 用这个较小的学习率更新参数
        optimizer.lr = warmup_lr

    # warmup结束后，就用正常学习率 lr=0.001
```

---

## 6.4 损失函数（Loss Function）—— 模型的"成绩单"

### 用一句话说清楚

**损失函数 = 给模型的预测打分，预测越错分数越高（分数越低越好）**

就像考试分数一样，只不过损失函数是"扣分制"——错得越多，损失越大。

### 生活类比：猜价格游戏

```
┌─────────────────────────────────────────────────────────────────┐
│                   电视购物"猜价格"游戏                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   商品真实价格：100元                                            │
│                                                                 │
│   玩家A猜：99元  → 误差1元   → 损失很小（几乎猜对了！）           │
│   玩家B猜：80元  → 误差20元  → 损失中等（差得有点多）             │
│   玩家C猜：10元  → 误差90元  → 损失很大（猜得太离谱！）           │
│                                                                 │
│   损失函数的作用：                                               │
│   "告诉模型它的预测有多离谱，离谱程度用一个数字表示"             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### EZSpecificity用的损失函数：BCEWithLogitsLoss

**中文名：二分类交叉熵损失（听不懂没关系，看下面的解释）**

```
┌─────────────────────────────────────────────────────────────────┐
│                用大白话解释BCEWithLogitsLoss                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   任务：判断"这个酶能不能催化这个底物"                            │
│   ├── 真实答案：能(1) 或 不能(0)                                 │
│   └── 模型预测：一个0到1之间的数，表示"能"的概率                  │
│                                                                 │
│   例子：                                                        │
│   ┌────────────┬────────────┬────────────┬────────────┐         │
│   │ 真实答案   │ 模型预测   │ 预测质量   │ 损失大小   │         │
│   ├────────────┼────────────┼────────────┼────────────┤         │
│   │ 能(1)      │ 0.95       │ 很准！     │ 很小(0.05) │         │
│   │ 能(1)      │ 0.50       │ 一般般     │ 中等(0.69) │         │
│   │ 能(1)      │ 0.05       │ 完全猜反了 │ 很大(3.00) │         │
│   │ 不能(0)    │ 0.05       │ 很准！     │ 很小(0.05) │         │
│   │ 不能(0)    │ 0.95       │ 完全猜反了 │ 很大(3.00) │         │
│   └────────────┴────────────┴────────────┴────────────┘         │
│                                                                 │
│   规律：预测越准，损失越小；预测越错，损失越大                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 特别重要：sample_weight（样本权重）

EZSpecificity有个特别的问题：**正负样本不平衡！**

```
┌─────────────────────────────────────────────────────────────────┐
│                       数据不平衡问题                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   EZSpecificity的数据：                                         │
│   ├── 能反应（正样本）：约56,000个  ← 只占 10%                   │
│   └── 不能反应（负样本）：约530,000个 ← 占 90%                   │
│                                                                 │
│   【问题】模型可能"偷懒"：                                       │
│   ├── 如果模型总是预测"不能反应"                                 │
│   ├── 准确率也能达到90%！（因为90%的数据确实是"不能反应"）       │
│   └── 但这样的模型完全没用！根本不能识别能反应的酶               │
│                                                                 │
│   【解决方案】给稀有样本更高的权重：                              │
│   ├── 预测错一个"能反应" → 惩罚 ×9（因为稀有，要更重视！）        │
│   └── 预测错一个"不能反应" → 惩罚 ×1（数量多，损失一个没关系）   │
│                                                                 │
│   效果：模型被迫认真学习稀有的正样本，不能靠"偷懒"混分            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 在EZSpecificity代码中长什么样？

代码位置：[ss.py:156-161](src/Models/ss.py#L156-L161)

```python
def get_loss(self, x, logits, stage):
    # 计算每个样本的损失
    loss_per_sample = torch.nn.BCEWithLogitsLoss(reduction='none')(
        logits,     # 模型的预测
        x.label     # 真实答案
    )

    # 乘以样本权重（正样本权重高，负样本权重低）
    weighted_loss = loss_per_sample * x.sample_weight

    # 返回平均损失
    return weighted_loss.mean()
```

---

## 6.5 评估指标（Metrics）—— 模型的"体检报告"

### 用一句话说清楚

**评估指标 = 用来判断模型到底好不好的"体检项目"**

就像人的健康不能只看体重，模型的好坏也不能只看准确率。EZSpecificity用两个指标：AUC和AUPR。

### 为什么不用"准确率"？

```
┌─────────────────────────────────────────────────────────────────┐
│                   准确率的"陷阱"                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   回顾一下数据不平衡问题：                                        │
│   ├── 能反应：10%                                               │
│   └── 不能反应：90%                                              │
│                                                                 │
│   如果模型"全猜不能反应"：                                       │
│   ├── 准确率 = 90%！看起来很高？                                 │
│   └── 但实际上这模型完全没用，一个正样本都找不到                   │
│                                                                 │
│   所以需要更好的评估指标！                                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### AUC：模型的"区分能力"

**AUC = Area Under ROC Curve（ROC曲线下面积）**

```
┌─────────────────────────────────────────────────────────────────┐
│                   用大白话解释AUC                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   想象一个"配对比较"游戏：                                        │
│   ├── 随机拿出一个正样本（能反应的）                              │
│   ├── 随机拿出一个负样本（不能反应的）                            │
│   └── 问模型：哪个是正样本？                                     │
│                                                                 │
│   AUC = 模型答对的概率                                           │
│   ├── AUC = 0.5：瞎猜（50%概率答对）                             │
│   ├── AUC = 0.8：比较厉害（80%概率答对）                         │
│   ├── AUC = 0.9：很厉害（90%概率答对）                           │
│   └── AUC = 1.0：完美（100%答对）                                │
│                                                                 │
│   EZSpecificity的AUC约0.85，意味着：                             │
│   "如果随机拿一对数据，模型85%的概率能正确区分谁是正样本"         │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### AUPR：模型的"找正样本能力"

**AUPR = Area Under Precision-Recall Curve（PR曲线下面积）**

```
┌─────────────────────────────────────────────────────────────────┐
│                   用大白话解释AUPR                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   想象你在一堆沙子里找金子（正样本）：                             │
│   ├── 精确率(Precision)：你捡起来的东西里，有多少是真金子？      │
│   └── 召回率(Recall)：所有金子里，你找到了多少？                  │
│                                                                 │
│   例子：                                                        │
│   ├── 模型说"我找到了100个正样本"                               │
│   ├── 其中80个真的是正样本 → 精确率 = 80%                        │
│   ├── 实际共有200个正样本                                        │
│   └── 你找到了80个 → 召回率 = 40%                                │
│                                                                 │
│   AUPR综合衡量这两个指标                                         │
│   ├── AUPR高 = 既找得准，又找得全                                │
│   └── 在正样本稀少时（如EZSpecificity），AUPR比AUC更重要！       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### AUC vs AUPR：什么时候看哪个？

| 情况 | 看AUC | 看AUPR |
|------|-------|--------|
| 正负样本数量差不多 | ✓ 推荐 | 也行 |
| 正样本很少（如10%） | 可能有误导 | ✓ **更重要** |
| EZSpecificity | 参考 | ✓ **重点关注** |

### 在EZSpecificity代码中长什么样？

代码位置：[ss.py:184-202](src/Models/ss.py#L184-L202)

```python
def get_auc_aupr(self, logits, label, name, stage):
    from sklearn import metrics

    # 计算AUC
    fpr, tpr, _ = metrics.roc_curve(label, logits)
    auc = metrics.auc(fpr, tpr)

    # 计算AUPR
    aupr = metrics.average_precision_score(label, logits)

    # 记录到日志
    print(f"AUC: {auc}")    # 比如 0.85
    print(f"AUPR: {aupr}")  # 比如 0.72

    return auc, aupr
```

---

## 6.6 数据加载器（DataLoader）—— 数据的"传送带"

### 用一句话说清楚

**DataLoader = 把数据分批送给模型的"传送带"**

就像工厂流水线一样，数据不能一股脑全塞给模型，而是要有序地、一批一批地喂。

### 生活类比：食堂打饭

```
┌─────────────────────────────────────────────────────────────────┐
│                   食堂打饭 vs 模型训练                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   【食堂场景】                                                   │
│   ├── 全校1000个学生要吃饭                                       │
│   ├── 不可能同时给1000人打饭（太混乱了）                          │
│   └── 正确做法：每次叫32个人来打饭，一批一批来                    │
│                                                                 │
│   【模型训练】                                                   │
│   ├── 有439,887条数据要训练                                      │
│   ├── 不可能同时处理全部（显存放不下，也没效率）                  │
│   └── 正确做法：每次取32条数据，一批一批训练                      │
│                                                                 │
│   DataLoader的作用：                                             │
│   "自动把数据分成小批，按顺序（或打乱后）送给模型"               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### DataLoader的关键设置

```
┌─────────────────────────────────────────────────────────────────┐
│                  DataLoader的4个关键参数                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   1. batch_size = 32（每批多少条数据）                           │
│      ├── 为什么是32？                                           │
│      ├── 太小（如1）：训练太慢，而且不稳定                        │
│      ├── 太大（如10000）：显存放不下                             │
│      └── 32是个常用的折中值                                     │
│                                                                 │
│   2. shuffle = True/False（是否打乱顺序）                        │
│      ├── 训练时 = True（打乱）                                   │
│      │   └── 为什么？防止模型记住数据顺序而不是学规律            │
│      └── 验证/测试时 = False（不打乱）                           │
│          └── 为什么？保持顺序方便检查结果                        │
│                                                                 │
│   3. num_workers = 16（多少个进程并行加载数据）                   │
│      ├── 比喻：请了16个帮手同时准备数据                          │
│      └── 加快数据准备速度，GPU不用等数据                         │
│                                                                 │
│   4. follow_batch（图神经网络专用，先不用理解）                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 为什么训练时要打乱（shuffle）？

```
┌─────────────────────────────────────────────────────────────────┐
│                    打乱的重要性                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   假设数据原本是按标签排序的：                                    │
│   [正,正,正,...,正(56000个), 负,负,负,...,负(530000个)]          │
│                                                                 │
│   不打乱的问题：                                                 │
│   ├── 第1-1750批：全是正样本                                    │
│   │   └── 模型学到："所有数据都是正的！"                         │
│   ├── 第1751-18000批：全是负样本                                 │
│   │   └── 模型学到："不对，都是负的！"                           │
│   └── 模型来回震荡，学不好                                      │
│                                                                 │
│   打乱后：                                                       │
│   [负,正,负,负,正,负,正,负,负,负,正,...]                        │
│   ├── 每一批都有正有负                                          │
│   ├── 模型每次都能同时学习两种样本                               │
│   └── 学习更稳定，收敛更快                                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 在EZSpecificity代码中长什么样？

代码位置：[brenda.py:38-50](src/Datasets/brenda.py#L38-L50)

```python
def train_dataloader(self):
    return DataLoader(
        data,
        batch_size=32,        # 每批32条
        shuffle=True,         # 打乱顺序
        num_workers=16        # 16个进程并行加载
    )

def val_dataloader(self):
    return DataLoader(
        data,
        batch_size=32,        # 每批32条
        shuffle=False,        # 不打乱（保持顺序）
        num_workers=16
    )
```

---

## 6.7 所有组件的协作关系（一张图看懂）

### 用一句话说清楚

**这些组件就像一条流水线上的工人，各司其职，协同工作**

### 组件协作全景图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    EZSpecificity 训练组件协作图                               │
│                   （像工厂流水线一样理解它！）                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   【原材料仓库】                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  训练集 439,887条                                                   │   │
│   │  验证集 43,988条                                                    │   │
│   │  测试集 102,640条                                                   │   │
│   └───────────────────────────────┬─────────────────────────────────────┘   │
│                                   │                                         │
│                                   ▼                                         │
│   【传送带】DataLoader                                                       │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  "我负责把数据分成小批（32条一批），送给模型"                         │   │
│   │  "训练时我会打乱顺序，验证时保持原样"                                 │   │
│   └───────────────────────────────┬─────────────────────────────────────┘   │
│                                   │ 每次送32条数据                           │
│                                   ▼                                         │
│   【加工车间】模型（SS）                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  输入：32对（酶，底物）                                              │   │
│   │  输出：32个预测值（0-1之间，表示"能反应"的概率）                      │   │
│   └───────────────────────────────┬─────────────────────────────────────┘   │
│                                   │ 32个预测值                               │
│                                   ▼                                         │
│   【质检员】损失函数（BCEWithLogitsLoss）                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  "我负责对比预测和真实答案，算出'错了多少'"                           │   │
│   │  "正样本预测错了惩罚更重（×9），负样本错了惩罚轻一点（×1）"           │   │
│   │  输出：一个损失值（比如0.35）                                         │   │
│   └───────────────────────────────┬─────────────────────────────────────┘   │
│                                   │ 损失值                                   │
│                                   ▼                                         │
│   【智能老师】Adam优化器 + Warmup + 学习率调度器                             │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  Adam："根据损失，智能地调整模型参数，活跃的参数小步走，安静的大步走" │   │
│   │  Warmup："前5轮我先热身，学习率从小到大慢慢来"                        │   │
│   │  调度器："如果连续10轮没进步，我就把学习率减半"                       │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│   ═══════════════════════════════════════════════════════════════════════   │
│                                                                             │
│   【每轮结束时的检查站】                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  验证集评估：用AUC和AUPR检查模型学得怎么样                            │   │
│   │  ├── 有进步？→ 保存模型！                                            │   │
│   │  ├── 停滞了？→ 学习率调度器降低学习率                                │   │
│   │  └── 连续20轮没进步？→ 早停！结束训练                                │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 组件调用顺序（时间线）

```
训练开始前：
├── 加载数据 → 创建DataLoader → 创建Adam优化器 → 设置Warmup和学习率调度器

每个Batch：
├── DataLoader取32条数据
├── 模型预测32个结果
├── 损失函数计算"错了多少"
└── Adam优化器更新参数（Warmup期间学习率较小）

每轮Epoch结束：
├── 用验证集计算AUC和AUPR
├── 学习率调度器检查：需要降低学习率吗？
└── 早停检查：需要停止训练吗？

训练结束后：
└── 加载最佳模型，用测试集评估最终结果
```

---

## 6.8 配置参数速查表

### 用一句话说清楚

**配置文件 = 训练前要填的"表格"，告诉程序各种参数用什么值**

### 关键参数一览表

下面是EZSpecificity训练时常用的参数，以及它们的含义：

| 参数名 | 默认值 | 大白话含义 | 调整建议 |
|--------|--------|------------|----------|
| **optimizer** | adam | 用哪个优化器 | 一般不用改，adam够用 |
| **lr** | 0.001 | 学习速度（步子大小） | 太大会震荡，太小会太慢 |
| **min_lr** | 0.000001 | 学习率的最低值 | 一般不用改 |
| **warmup_epochs** | 5 | 热身几轮 | 一般5轮就够 |
| **sched_factor** | 0.5 | 学习率减速时减到原来的多少 | 0.5表示减半 |
| **sched_patience** | 10 | 停滞几轮才减速 | 太小会过早减速 |
| **batch_size** | 32 | 每批处理多少条数据 | 显存不够就减小 |
| **max_epochs** | 100 | 最多训练几轮 | 一般会被早停提前结束 |

### 配置文件长什么样？

```yaml
# 这是一个YAML格式的配置文件（像填表格一样简单）

training:
  optimizer: "adam"        # 优化器：用adam
  lr: 0.001                # 学习率：0.001
  min_lr: 0.000001         # 最低学习率
  warmup_epochs: 5         # 热身5轮
  sched_factor: 0.5        # 减速时减半
  sched_patience: 10       # 停滞10轮才减速
  max_epochs: 100          # 最多100轮
  batch_size: 32           # 每批32条

data:
  train_data_path: "训练集文件路径"
  val_data_path: "验证集文件路径"
  test_data_path: "测试集文件路径"
```

### 新手建议

```
┌─────────────────────────────────────────────────────────────────┐
│                    新手应该怎么设参数？                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   1. 先用默认值跑一遍，看看效果怎么样                            │
│                                                                 │
│   2. 如果显存不够（Out of Memory）：                             │
│      └── 减小 batch_size（32→16→8）                             │
│                                                                 │
│   3. 如果训练不稳定（loss上蹿下跳）：                            │
│      └── 减小 lr（0.001→0.0005→0.0001）                         │
│                                                                 │
│   4. 如果训练太慢：                                              │
│      └── 增大 lr（谨慎操作，可能会不稳定）                       │
│                                                                 │
│   5. 其他参数一般不用动！                                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

<a name="第七章"></a>
# 第七章：代码逐行解读

## 7.1 完整的训练脚本（重构版，便于理解）

```python
"""
EZSpecificity 训练脚本 - 教学版
这不是原始代码，而是简化后便于理解的版本
"""

import pytorch_lightning as pl
from src.Datasets.brenda import Singledataset
from src.Models.ss import SS

def train_ezspecificity():
    """训练EZSpecificity模型的完整流程"""

    # ═══════════════════════════════════════════════════════════
    # 第1步：配置训练参数
    # ═══════════════════════════════════════════════════════════

    config = {
        'data': {
            # 数据文件路径（使用Fold 0）
            'train_data_path': 'ESIBank/brenda/random_split/training_datas_0.csv',
            'val_data_path': 'ESIBank/brenda/random_split/val_datas_0.csv',
            'test_data_path': 'ESIBank/brenda/random_split/testing_datas_0.csv',

            # 每次处理多少条数据
            'batch_size': 32,
            # 为什么是32？
            # - 太小（如1）：训练很慢，而且不稳定
            # - 太大（如1000）：显存不够，而且可能错过细节
            # - 32是常用的折中选择
        },
        'training': {
            # 学习率：每次更新参数的幅度
            'lr': 0.001,
            # 为什么是0.001？
            # - 太大（如0.1）：参数更新太猛，可能"跳过"最优点
            # - 太小（如0.00001）：学习太慢，要训练很久
            # - 0.001是Adam优化器的常用初始值

            # 最多训练多少轮
            'max_epochs': 100,

            # 验证频率：每多少轮验证一次
            'val_frequency': 1,  # 每1轮验证一次

            # 早停耐心：如果连续多少轮没有进步就停止
            'patience': 20,
        },
        'model': {
            # 模型隐藏层维度
            'hidden_dim': 128,
            # 为什么是128？
            # - 太小（如16）：模型"记不住"复杂的规律
            # - 太大（如1024）：容易过拟合，计算也慢
            # - 128是常用的折中选择
        }
    }

    # ═══════════════════════════════════════════════════════════
    # 第2步：准备数据
    # ═══════════════════════════════════════════════════════════

    print("正在加载数据...")
    data_module = Singledataset(config)
    # data_module.train_df: 439,887 条训练数据
    # data_module.val_df:    43,988 条验证数据
    # data_module.test_df:  102,640 条测试数据

    print(f"训练集: {len(data_module.train_df)} 条")
    print(f"验证集: {len(data_module.val_df)} 条")
    print(f"测试集: {len(data_module.test_df)} 条")

    # ═══════════════════════════════════════════════════════════
    # 第3步：创建模型
    # ═══════════════════════════════════════════════════════════

    print("\n正在创建模型...")
    model = SS(config)
    # 此时模型参数是随机初始化的
    # 预测能力相当于瞎猜（AUC约0.5）

    # 模型参数数量
    total_params = sum(p.numel() for p in model.parameters())
    print(f"模型参数数量: {total_params:,}")  # 比如 "5,234,567"

    # ═══════════════════════════════════════════════════════════
    # 第4步：配置训练器
    # ═══════════════════════════════════════════════════════════

    # 设置回调函数
    callbacks = [
        # 早停：如果验证集AUC连续20轮没有提升，就停止训练
        pl.callbacks.EarlyStopping(
            monitor='auc/val',     # 监控验证集AUC
            patience=20,           # 耐心值
            mode='max',            # 目标是最大化AUC
            verbose=True           # 打印停止信息
        ),

        # 模型检查点：保存验证集上表现最好的模型
        pl.callbacks.ModelCheckpoint(
            monitor='auc/val',          # 监控验证集AUC
            mode='max',                 # 保存AUC最高的
            save_top_k=1,               # 只保存最好的1个
            filename='best_model',      # 文件名
            dirpath='saved_model/',     # 保存路径
            verbose=True
        )
    ]

    # 创建训练器
    trainer = pl.Trainer(
        max_epochs=100,              # 最多100轮
        gpus=1,                      # 使用1块GPU
        callbacks=callbacks,         # 使用上面定义的回调
        check_val_every_n_epoch=1,   # 每轮都验证
    )

    # ═══════════════════════════════════════════════════════════
    # 第5步：开始训练！
    # ═══════════════════════════════════════════════════════════

    print("\n开始训练...")
    print("=" * 60)

    trainer.fit(model, datamodule=data_module)
    # 这一行代码会执行：
    # - 100轮训练（或提前早停）
    # - 每轮结束后在验证集上评估
    # - 自动保存最佳模型

    # ═══════════════════════════════════════════════════════════
    # 第6步：训练结束后的最终测试
    # ═══════════════════════════════════════════════════════════

    print("\n" + "=" * 60)
    print("训练结束！正在进行最终测试...")

    # 加载验证集上表现最好的模型（不是最后一个模型！）
    best_model = SS.load_from_checkpoint('saved_model/best_model.ckpt')

    # 在测试集上评估
    trainer.test(best_model, datamodule=data_module)

    # 输出结果
    print("\n" + "=" * 60)
    print("最终结果（在测试集上）：")
    print(f"  AUC:  {best_model.test_auc:.4f}")   # 比如 0.8521
    print(f"  AUPR: {best_model.test_aupr:.4f}")  # 比如 0.7834
    print("=" * 60)

    # 这个AUC就是论文里报告的数字！

if __name__ == "__main__":
    train_ezspecificity()
```

## 7.2 训练过程中的输出示例

```
正在加载数据...
训练集: 439,887 条
验证集: 43,988 条
测试集: 102,640 条

正在创建模型...
模型参数数量: 5,234,567

开始训练...
============================================================

Epoch 1/100
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13746/13746 [05:23<00:00]
训练损失: 0.6821
验证集 AUC: 0.6234, AUPR: 0.5123
→ 新的最佳模型！已保存。

Epoch 2/100
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13746/13746 [05:21<00:00]
训练损失: 0.5432
验证集 AUC: 0.7156, AUPR: 0.6234
→ 新的最佳模型！已保存。

...（中间省略）...

Epoch 45/100
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13746/13746 [05:20<00:00]
训练损失: 0.1234
验证集 AUC: 0.8521, AUPR: 0.7834
→ 新的最佳模型！已保存。

Epoch 46/100
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13746/13746 [05:19<00:00]
训练损失: 0.1198
验证集 AUC: 0.8519, AUPR: 0.7831
（没有进步，耐心剩余 19 轮）

...（继续训练但验证集不再提升）...

Epoch 65/100
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13746/13746 [05:18<00:00]
训练损失: 0.0567
验证集 AUC: 0.8423, AUPR: 0.7654
（没有进步，耐心剩余 0 轮）
★ 早停触发！连续20轮没有进步，停止训练。

============================================================
训练结束！正在进行最终测试...
加载模型: saved_model/best_model.ckpt (第45轮保存的)

============================================================
最终结果（在测试集上）：
  AUC:  0.8521
  AUPR: 0.7834
============================================================
```

---

<a name="第八章"></a>
# 第八章：常见问题解答

## Q1: 为什么训练损失一直下降，但验证集准确率不再上升？

```
┌─────────────────────────────────────────────────────────────────┐
│                        这就是过拟合！                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   训练损失下降 = 模型在训练数据上越来越"准"                       │
│   验证集不上升 = 但对新数据的预测能力没有提升                      │
│                                                                 │
│   类比：                                                        │
│   - 你把100道练习题的答案都背下来了（训练损失→0）               │
│   - 但考试出了101道题，你还是不会（验证准确率停滞）              │
│                                                                 │
│   解决方案：                                                    │
│   1. Early Stopping：在验证集开始下降时停止训练                 │
│   2. 正则化：给模型加"惩罚"，让它不要过度记忆细节                │
│   3. 更多数据：数据越多，越不容易过拟合                         │
│   4. 简化模型：参数太多的模型更容易过拟合                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Q2: batch_size 是什么？为什么不是1？为什么不是全部？

```
batch_size = 每次给模型看多少条数据

┌─────────────────────────────────────────────────────────────────┐
│ batch_size = 1 （随机梯度下降 SGD）                              │
├─────────────────────────────────────────────────────────────────┤
│ 优点：每条数据都能影响参数更新，不会漏掉细节                      │
│ 缺点：                                                          │
│   - 训练非常慢（439,887次更新/轮）                               │
│   - 更新方向不稳定（一条数据可能是噪声）                         │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│ batch_size = 439,887 （全部数据，批量梯度下降）                  │
├─────────────────────────────────────────────────────────────────┤
│ 优点：更新方向很稳定（考虑了全部数据）                           │
│ 缺点：                                                          │
│   - 显存放不下（需要几十GB）                                     │
│   - 每轮只更新1次参数，收敛太慢                                  │
│   - 容易陷入局部最优                                            │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│ batch_size = 32 （小批量梯度下降 Mini-batch SGD）                │
├─────────────────────────────────────────────────────────────────┤
│ 折中方案：                                                      │
│   - 每轮更新 439,887÷32 ≈ 13,746 次，足够多                     │
│   - 每次用32条数据平均，方向比较稳定                             │
│   - 显存可以放得下                                              │
│   - 适度的随机性有助于跳出局部最优                               │
└─────────────────────────────────────────────────────────────────┘
```

## Q3: 学习率 lr 是什么？

```
学习率 = 每次更新参数时"走多大一步"

┌─────────────────────────────────────────────────────────────────┐
│                       学习率的影响                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   目标：找到损失最低的点（山谷底部）                              │
│                                                                 │
│   学习率太大（lr=0.1）：                                         │
│   ──▶ ──▶ ──▶ ──▶     步子太大，直接跨过山谷，永远到不了底       │
│                                                                 │
│   学习率太小（lr=0.00001）：                                     │
│   →→→→→→→→→...       步子太小，需要走很久才能到底                │
│                                                                 │
│   学习率合适（lr=0.001）：                                       │
│   ─▶ ─▶ ─▶ ▶          步子刚好，稳步走到山谷底部                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Q4: 为什么要用验证集来选择"最佳模型"，而不是直接用最后一轮的模型？

```
┌─────────────────────────────────────────────────────────────────┐
│                       不同轮次的模型                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   第1轮模型：刚开始学，什么都不会                                │
│   第45轮模型：学到了通用规律，泛化能力最强 ← 最佳模型！          │
│   第65轮模型：开始背答案了，对新数据表现变差                     │
│                                                                 │
│   如果直接用第65轮的模型：                                       │
│   - 在训练集上表现很好（因为背住了）                            │
│   - 在测试集上表现变差（因为是新题）                            │
│                                                                 │
│   用验证集选出第45轮的模型：                                     │
│   - 在验证集上表现最好                                          │
│   - 在测试集上表现也很好（泛化能力强）                          │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Q5: 为什么测试集只能用一次？

```
┌─────────────────────────────────────────────────────────────────┐
│                    测试集"污染"问题                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   假设你偷看了测试集，然后：                                     │
│   - 发现测试集里"P450酶"特别多                                   │
│   - 于是你调整模型，让它对"P450酶"预测更准                       │
│   - 测试集得分从85%提升到90%！                                   │
│                                                                 │
│   问题：                                                        │
│   - 这个90%是"针对测试集优化"得到的                              │
│   - 对真正的新数据，模型可能还是只有85%                          │
│   - 你报告的90%是虚假的"好成绩"                                  │
│                                                                 │
│   所以：                                                        │
│   - 测试集必须"封印"到最后一刻                                   │
│   - 用验证集来调整模型                                          │
│   - 测试集只在论文最终报告时使用一次                            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Q6: 我看到的 random_split 文件夹里有4套数据（0-3），是都要用吗？

```
random_split/
├── training_datas_0.csv  ┐
├── val_datas_0.csv       ├─ Fold 0（一种划分方式）
├── testing_datas_0.csv   ┘
├── training_datas_1.csv  ┐
├── val_datas_1.csv       ├─ Fold 1（另一种划分方式）
├── testing_datas_1.csv   ┘
├── training_datas_2.csv  ┐
├── val_datas_2.csv       ├─ Fold 2
├── testing_datas_2.csv   ┘
├── training_datas_3.csv  ┐
├── val_datas_3.csv       ├─ Fold 3
└── testing_datas_3.csv   ┘

理想做法（4-Fold交叉验证）：
1. 用 Fold 0 训练模型 → 测试准确率 85.2%
2. 用 Fold 1 训练模型 → 测试准确率 84.8%
3. 用 Fold 2 训练模型 → 测试准确率 85.5%
4. 用 Fold 3 训练模型 → 测试准确率 84.9%
5. 报告：准确率 85.1% ± 0.3%

EZSpecificity实际做法：
- 只用了 Fold 0
- 报告的是单次实验的结果
```

---

## 总结

| 概念 | 一句话解释 |
|------|-----------|
| **训练集** | 模型用来学习的"课本"，可以反复看 |
| **验证集** | 监控学习进度的"周测"，用来挑选最佳模型 |
| **测试集** | 最终评估的"高考"，只能用一次 |
| **Epoch** | 把训练集完整过一遍叫一轮 |
| **Batch** | 每次给模型看的数据量（如32条） |
| **学习率** | 参数更新的步长大小（每步走多远） |
| **损失函数** | 预测错误的程度，越小越好 |
| **Adam优化器** | 智能老师，帮模型高效学习 |
| **Warmup** | 训练前热身，学习率从小到大 |
| **学习率调度器** | 停滞时自动降低学习率 |
| **AUC** | 模型区分正负样本的能力（0.5-1.0） |
| **AUPR** | 模型找正样本的能力（正样本少时更重要）|
| **过拟合** | 模型"背答案"，对新数据表现差 |
| **早停** | 验证集不再进步时停止训练 |
| **Fold** | 数据的一种划分方案，每个Fold都包含全部数据 |
| **交叉验证** | 用多种划分方式多次实验，取平均结果 |

---

**文档结束**

**创建者**：Claude
**审核者**：Codex（代码逻辑）、Gemini（通俗性）
